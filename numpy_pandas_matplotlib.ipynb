{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the NumPy Stack\n",
    "\n",
    "# NumPy\n",
    "\n",
    "The NumPy module is a Python package that implements Linear Algebra functionality in Python, and is the basis of nearly all modules used for Data Science in industry.  This will allow us to do fast and easy vector and matrix operations.  NumPy is highly optimized for numerical calculations, and has much of its back-end written in C.  So, it's also going to run a lot faster than normal Python code.\n",
    "\n",
    "We start by importing the NumPy module.  By convention, as we import NumPy, we shorten its name to \"np\", as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T08:50:31.689000Z",
     "start_time": "2018-09-12T08:50:31.390000Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported the module, the first object within NumPy we will look at is the array.\n",
    "\n",
    "## NumPy Arrays\n",
    "\n",
    "### Creating Arrays\n",
    "\n",
    "NumPy Arrays can be either one-dimensional or two-dimensional.  The one-dimensional array can be thought of as a vector.  The two-dimensional array can be thought of as a matrix.  We can create these by either casting a Python list as an array, or we can generate an array in a number of different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T09:39:41.225000Z",
     "start_time": "2018-08-20T09:39:41.194000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting a list into an array\n",
    "\n",
    "l = [1,2,3]\n",
    "a = np.array(l)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate an array using the ```arange()``` function, which takes three arguements, ```start```, ```stop```, and ```step```.  If nothing is passed for the ```start``` argument, it is assumed to be ```0```, and if nothing is passed for the ```step``` argument, the step is assumed to be ```1```.  Notice that the ```stop``` argument is not included in the range generated (just like the normal ```range()``` function in Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:49:07.913000Z",
     "start_time": "2018-08-10T12:49:07.905000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:49:11.991000Z",
     "start_time": "2018-08-10T12:49:11.983000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:49:22.820000Z",
     "start_time": "2018-08-10T12:49:22.811000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7, 9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3, 11, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also certain special functions for generating certain types of arrays that may be useful in certain calculations.  the function ```zeros``` generates an array of all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:50:26.673000Z",
     "start_time": "2018-08-10T12:50:26.641000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:51:05.928000Z",
     "start_time": "2018-08-10T12:51:05.920000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((4, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the function```ones``` generates an array of all ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:51:20.081000Z",
     "start_time": "2018-08-10T12:51:20.069000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:51:21.057000Z",
     "start_time": "2018-08-10T12:51:21.049000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((4,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate an array that is a sequence between two points using the ```linspace()``` function.  This function is similar to the ```arange()```.  It also takes three arguments ```start```, ```stop```, and ```n_steps```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:52:03.007000Z",
     "start_time": "2018-08-10T12:52:02.999000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,\n",
       "        5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 10, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily create an identity matrix of any size using either the ```eye()``` function, or the ```identity()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:44.195000Z",
     "start_time": "2018-05-31T09:17:44.187000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:44.638000Z",
     "start_time": "2018-05-31T09:17:44.630000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these functions only require one argument, since an identity matrix must be square ($n \\times n$), we can just specify ```n```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a variety of methods for creating randomly generated arrays.  These can all be found in the ```random``` sub module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:46.034000Z",
     "start_time": "2018-05-31T09:17:46.026000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90157392, -0.35810523,  1.19218259, -0.638735  ,  0.27005714],\n",
       "       [ 0.7576297 ,  0.65659721, -0.71212639,  0.25641297, -1.42523939],\n",
       "       [ 1.05494824, -0.39642985,  0.15274572,  1.04354782,  0.08127806],\n",
       "       [ 0.17641942,  0.03843056, -0.14245144,  0.95498997,  0.56100064]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate numbers from the Standard Normal distribution\n",
    "\n",
    "np.random.randn(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:46.551000Z",
     "start_time": "2018-05-31T09:17:46.539000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47509625, 0.81733751, 0.3965635 , 0.50190242, 0.90600861],\n",
       "       [0.13397918, 0.60897764, 0.93595223, 0.51261453, 0.52444688],\n",
       "       [0.85979127, 0.67897626, 0.62116908, 0.66064461, 0.09287412],\n",
       "       [0.73548006, 0.01003759, 0.14252235, 0.75739945, 0.96897057]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate numbers from a Uniform distribution between 0 and 1\n",
    "\n",
    "np.random.random((4,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate random numbers from any named distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:47.906000Z",
     "start_time": "2018-05-31T09:17:47.874000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.43989943,  0.33283284, -3.39478332, -0.05119575, -1.17939584,\n",
       "       -2.49422989,  0.99744007, -1.96995493,  1.0396065 , -2.38949074])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.laplace(size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:48.647000Z",
     "start_time": "2018-05-31T09:17:48.639000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02320204,  1.21183852, -0.5749149 ,  0.42625337,  1.40075635],\n",
       "       [-0.66924381, -0.57472231,  2.49616142,  0.42475732, -1.15837486],\n",
       "       [ 0.10106318,  0.97892206,  0.03703811,  0.0934123 , -0.45738134],\n",
       "       [-2.29963187, -0.28431472,  0.36672991, -1.37577146,  1.97074355]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.laplace(size = (4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:49.168000Z",
     "start_time": "2018-05-31T09:17:49.160000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47320938, 0.16106393, 1.55520015, 0.42051955, 0.74289384,\n",
       "       4.61965857, 0.30455112, 1.43367874, 1.64850603, 1.30792177])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.lognormal(size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Arrays\n",
    "\n",
    "Arrays can be manipulated in a variety of ways.  Let's look at the shape of an array, and then see how that can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:55:51.215000Z",
     "start_time": "2018-08-10T12:55:51.207000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.array([1,2,3,4,5,6])\n",
    "arr2 = np.array([[1,2],[3,4]])\n",
    "\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:51.329000Z",
     "start_time": "2018-05-31T09:17:51.317000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1.shape     # Check the shape attribute of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:51.736000Z",
     "start_time": "2018-05-31T09:17:51.728000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:17:52.197000Z",
     "start_time": "2018-05-31T09:17:52.189000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ```reshape()``` method to change the shape of these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:57:15.157000Z",
     "start_time": "2018-08-10T12:57:15.149000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1.reshape(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T17:30:09.460000Z",
     "start_time": "2018-05-29T17:30:09.452000Z"
    }
   },
   "source": [
    "Notice that this change doesn't happen \"in place\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:57:19.069000Z",
     "start_time": "2018-08-10T12:57:19.061000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the shape of an array permanently, we need to store this change in a variable.  We can even store this change over the old array by assigning the reshaped array to the same variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:58:25.228000Z",
     "start_time": "2018-08-10T12:58:25.220000Z"
    }
   },
   "outputs": [],
   "source": [
    "arr1 = arr1.reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:58:26.421000Z",
     "start_time": "2018-08-10T12:58:26.413000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:58:42.140000Z",
     "start_time": "2018-08-10T12:58:42.132000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform mathematical operations with NumPy arrays.  In this way, NumPy arrays behave much like the mathematical counterparts they represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:59:06.117000Z",
     "start_time": "2018-08-10T12:59:06.085000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.array([1,2,3])\n",
    "a2 = np.array([4,5,6])\n",
    "\n",
    "a1 + a2         # Vector Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:59:16.655000Z",
     "start_time": "2018-08-10T12:59:16.643000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 * a1          # Scalar Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T12:59:59.820000Z",
     "start_time": "2018-08-10T12:59:59.812000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10, 18])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 * a2         # Element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:00:01.701000Z",
     "start_time": "2018-08-10T13:00:01.673000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4. , 2.5, 2. ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 / a1         # Element-wise division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:00:06.543000Z",
     "start_time": "2018-08-10T13:00:06.511000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 ** 2         # Element-wise exponentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply functions to each element of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:00:22.779000Z",
     "start_time": "2018-08-10T13:00:22.771000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.71828183,  7.3890561 , 20.08553692])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(a1)     #e^a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays also support the dot product operation.  In the case of two vectors, this does exactly what it is supposed to do.  In the case of a matrix and a vector, or two matrices, the ```dot()``` function still performs the appropriate multiplication operation.  This can be done as either a function, or a method of the array itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:07:24.900000Z",
     "start_time": "2018-08-10T13:07:24.888000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a1, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:07:42.718000Z",
     "start_time": "2018-08-10T13:07:42.707000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.dot(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:10:13.104000Z",
     "start_time": "2018-08-10T13:10:13.096000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 32])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = np.array([[1,2,3], [4,5,6]])\n",
    "\n",
    "m1 + a1\n",
    "\n",
    "m1.dot(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:10:56.814000Z",
     "start_time": "2018-08-10T13:10:56.806000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22, 28],\n",
       "       [49, 64]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = np.array([[1,2],[3,4],[5,6]])\n",
    "\n",
    "m1.dot(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Another common manipulation or opertation of a matrix that NumPy makes very easy is taking the transpose of a matrix.  This is executed as a simple method of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:11:17.792000Z",
     "start_time": "2018-08-10T13:11:17.784000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2],[3,4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:11:30.733000Z",
     "start_time": "2018-08-10T13:11:30.725000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy also has some very convenient functions for summarising vectors and matrices.  For example, NumPy has built in functions for calculating the sum and mean of a vector or matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:12:05.580000Z",
     "start_time": "2018-08-10T13:12:05.572000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:12:06.771000Z",
     "start_time": "2018-08-10T13:12:06.763000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:18:06.752000Z",
     "start_time": "2018-05-31T09:18:06.744000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:18:07.622000Z",
     "start_time": "2018-05-31T09:18:07.614000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of matrices, we can either sum the entire array, or we can get the sum or each column or each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:12:16.802000Z",
     "start_time": "2018-08-10T13:12:16.790000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:15:32.884000Z",
     "start_time": "2018-08-10T13:15:32.872000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum each row\n",
    "\n",
    "np.sum(A, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:15:34.614000Z",
     "start_time": "2018-08-10T13:15:34.606000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum each column\n",
    "\n",
    "np.sum(A, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Selection\n",
    "\n",
    "NumPy arrays can be indexed using \"slice\" notation, just as with normal Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:15:58.423000Z",
     "start_time": "2018-08-10T13:15:58.411000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.array([1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "a1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:16:07.191000Z",
     "start_time": "2018-08-10T13:16:07.183000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 8, 9])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:16:20.562000Z",
     "start_time": "2018-08-10T13:16:20.554000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:16:22.771000Z",
     "start_time": "2018-08-10T13:16:22.763000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 8])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[-4:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix indexing can be done using the double bracket notation, as with embedded lists in Python, but they can also be indexed using the more natural two-dimensional index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:16:41.683000Z",
     "start_time": "2018-08-10T13:16:41.671000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.array([[1,2],[3,4]])\n",
    "\n",
    "m[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:16:57.055000Z",
     "start_time": "2018-08-10T13:16:57.043000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, indexing and selection can be done using conditional statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:17:09.281000Z",
     "start_time": "2018-08-10T13:17:09.273000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:17:15.741000Z",
     "start_time": "2018-08-10T13:17:15.733000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[a1 > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:17:22.349000Z",
     "start_time": "2018-08-10T13:17:22.341000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:17:40.609000Z",
     "start_time": "2018-08-10T13:17:40.601000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[m < 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Matrix Operations\n",
    "\n",
    "NumPy also provides access to many matrix operations from Linear Algebra in the ```linalg``` submodule.  We can find the inverse of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:17:53.703000Z",
     "start_time": "2018-08-10T13:17:53.695000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:18:13.415000Z",
     "start_time": "2018-08-10T13:18:13.339000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2. ,  1. ],\n",
       "       [ 1.5, -0.5]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:54:59.529000Z",
     "start_time": "2018-05-29T22:54:59.521000Z"
    }
   },
   "source": [
    "We can calculate the determinant of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:18:18.901000Z",
     "start_time": "2018-08-10T13:18:18.869000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0000000000000004"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:18:34.791000Z",
     "start_time": "2018-08-10T13:18:34.779000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 0, 3]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can calculate the trace of a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:18:42.379000Z",
     "start_time": "2018-08-10T13:18:42.371000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-29T22:58:50.582000Z",
     "start_time": "2018-05-29T22:58:50.578000Z"
    }
   },
   "source": [
    "Finally, we can solve a linear system of the form $Ax = b$ using the ```solve()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:19:14.993000Z",
     "start_time": "2018-08-10T13:19:14.989000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-10T13:19:21.776000Z",
     "start_time": "2018-08-10T13:19:21.768000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([1,2])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:18:27.028000Z",
     "start_time": "2018-05-31T09:18:26.988000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.22044605e-16, 5.00000000e-01])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linalg.inv(A).dot(b)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T09:18:27.990000Z",
     "start_time": "2018-05-31T09:18:27.981000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linalg.solve(A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumPy Problems\n",
    "\n",
    "#### 1.\n",
    "The admission fee at a small fair is 2.50 GBP for children and 5.00 GBP for adults.  On a given day, 2,400 tickets are sold and 8,000 GBP is collected.  How many children and how many adults attended?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T09:10:16.821000Z",
     "start_time": "2018-09-12T09:10:16.809000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children: [1600.]\n",
      "Adults: [800.]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 1], [2.5, 5]])\n",
    "b = np.array([[2400], [8000]])\n",
    "\n",
    "x = np.linalg.solve(A, b)\n",
    "print(\"Children: {c}\\nAdults: {a}\".format(c = x[0], a = x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T09:09:45.291000Z",
     "start_time": "2018-09-12T09:09:45.283000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2400 8000]\n",
      "[[2400]\n",
      " [8000]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([2400, 8000])\n",
    "print(x)\n",
    "x = np.expand_dims(x, 1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.\n",
    "Create a $6 \\times 6$ identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T09:13:17.218000Z",
     "start_time": "2018-09-12T09:13:17.190000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "Reverse the following vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T09:24:28.334000Z",
     "start_time": "2018-09-12T09:24:28.317000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 2, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.array([1,2,3,4])\n",
    "\n",
    "v_reverse = v[::-1]\n",
    "\n",
    "v_reverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.\n",
    "Some people are standing in a row in a park. There are trees between them which cannot be moved (marked by -1). Your task is to write a function to rearrange the people by their heights in ascending order without moving the trees.\n",
    "\n",
    "Example\n",
    "\n",
    "For ```a = [-1, 150, 190, 170, -1, -1, 160, 180]```, the output should be\n",
    "```sort_by_height(a) = [-1, 150, 160, 170, -1, -1, 180, 190]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T09:36:20.423000Z",
     "start_time": "2018-09-12T09:36:20.406000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1, 150, 160, 170,  -1,  -1, 180, 190])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_by_height(a):\n",
    "    a[a > 0] = np.sort(a[a > 0])\n",
    "    return a\n",
    "\n",
    "a = np.array([-1, 150, 190, 170, -1, -1, 160, 180])\n",
    "sort_by_height(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is an open-source library built on top of NumPy.  It introduces some new data structures to Python, including the DataFrame, which will be used to store general tabular data.  In order to use these tools, we have to import the Pandas library.  There is a strong convention in industry to reference Pandas by the shorthand \"pd\" as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T09:39:16.703000Z",
     "start_time": "2018-09-12T09:39:13.017000Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "Before we get to DataFrames, we're first going to look at another, more basic data structure in Pandas, the Series.  A Series is much like a NumPy Array, but a Series is able to have axis labels.  This means a Series can now be indexed by a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:09:07.033000Z",
     "start_time": "2018-09-11T13:09:07.026000Z"
    }
   },
   "outputs": [],
   "source": [
    "l = [1,2,3]                              # An ordinary Python list\n",
    "labels = [\"a\", \"b\", \"c\"]                 # A list of \"labels\"\n",
    "a = np.array([10, 20, 30])               # A NumPy Array\n",
    "d = {i:j for i, j in zip(labels, a)}     # An ordinary Python dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the objects defined above to demonstrate how we can create a Series.  First, we can simply pass in our Python list to the argument ```data```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:09:28.825000Z",
     "start_time": "2018-09-11T13:09:28.813000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(data = l)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the Series has been created with a default index (a sequence of integers starting at 0), since we didn't pass any index labels to the function.  If we'd like the Series to have an access label, we simply pass in a list of labels for the function to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:09:59.949000Z",
     "start_time": "2018-09-11T13:09:59.938000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(data = l, index = labels)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our Series has index labels \"a\", \"b\", and \"c\".  We can also use a NumPy array as our data, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:10:25.438000Z",
     "start_time": "2018-09-11T13:10:25.428000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int32"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(data = a, index = labels)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments ```data``` and ```index``` are actually positional arguments to the function, so we can just pass them in and Python will know what to do as long as we pass the data first and the label second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:10:44.127000Z",
     "start_time": "2018-09-11T13:10:44.118000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int32"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(a, labels)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also pass a dictionary into the ```Series()``` function, and it will assign the values as the data and the keys as the index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:11:05.300000Z",
     "start_time": "2018-09-11T13:11:05.287000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(d)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This added feature, the axis label, allows a Pandas Series to very efficiently and easily perform certain operations that would otherwise be more complex to execute.  For example, we can now index into a Series using the index label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:11:47.670000Z",
     "start_time": "2018-09-11T13:11:47.661000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:12:05.355000Z",
     "start_time": "2018-09-11T13:12:05.345000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[[\"a\", \"c\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being built upon NumPy Arrays, Series also support vectorized arithmetic operations, but these already powerful operations can be augmented further by the index label.  We see that we can perform vector addition with two Series as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:14:52.013000Z",
     "start_time": "2018-09-11T13:14:51.999000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    7\n",
       "2    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([1,2,3])\n",
    "s2 = pd.Series([4,5,6])\n",
    "\n",
    "s1 + s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at two Series with axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T10:34:05.996000Z",
     "start_time": "2018-05-31T10:34:05.948000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Australia    7.0\n",
       "Canada       NaN\n",
       "France       9.0\n",
       "Germany      NaN\n",
       "UK           3.0\n",
       "USA          3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([1,2,3,4,5], [\"USA\", \"UK\", \"Canada\", \"Australia\", \"France\"])\n",
    "s2 = pd.Series([1,2,3,4,5], [\"UK\", \"USA\", \"Australia\", \"France\", \"Germany\"])\n",
    "\n",
    "s3 = s1 + s2\n",
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T10:35:24.613000Z",
     "start_time": "2018-05-31T10:35:24.595000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Australia    False\n",
       "Canada        True\n",
       "France       False\n",
       "Germany       True\n",
       "UK           False\n",
       "USA          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though each country in ```s1``` has a different \"position\" in ```s2```, Python was able to match up the values assigned each country and perform this element-wise addition according to the axis label.  Notice that the countries that don't appear in both series show up as \"Not a Number\" (```NaN```).  This can be very powerful and convenient for making sure all of our calculations line up as they should while dealing with large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DataFrames\n",
    "\n",
    "While the Pandas Series object has a lot of useful properties and features, the real work horse of data manipulation in Python is the Pandas DataFrame, which is able to store general tabular data.  We can generate DataFrames for testing out concepts by casting dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:20:34.443000Z",
     "start_time": "2018-09-11T13:20:34.433000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [10, 15, 20], 'b': [20, 25, 40], 'c': [30, 35, 60]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {i:[j, j+5, j*2] for i,j in zip(labels, a)}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:20:52.163000Z",
     "start_time": "2018-09-11T13:20:52.146000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a   b   c\n",
       "0  10  20  30\n",
       "1  15  25  35\n",
       "2  20  40  60"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, in real-world data science applications our DataFrames will be the result of loading in some file given to us by a client (usually in some text format, like a .csv, or an Excel spreadsheet).  To appreciate the power of Pandas, let's first look at how we would load in such a data file using only NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T09:40:45.847000Z",
     "start_time": "2018-08-20T09:40:45.823000Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open(\"data_2d.csv\") as f:\n",
    "    for line in f:\n",
    "        row = line.split(\",\")\n",
    "        sample = map(float, row)\n",
    "        data.append(sample)\n",
    "        \n",
    "data = np.array(data)\n",
    "\n",
    "data[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That wasn't exactly hard, but it wasn't as easy as that could possibly be either.  Also, the object ```data``` is a matrix, so we're restricted in terms of the type of data we can store in it, because all of the elements of a matrix *must* be of the same type.  However, we know that a lot of real world data we encounter in industry is a mixture of data types.  One column might be numeric, while other columns are categorical variables, dates, or free text.  In this case, we definitely need a DataFrame.  We can read a file into a DataFrame quite easily.  Let's go ahead and load the same data set we just used to create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:28:05.609000Z",
     "start_time": "2018-09-11T13:28:05.586000Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_2d.csv\", header=None)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now *that* was easy.  And the object ```data``` is now a Pandas DataFrame, which has a number of useful methods and features.  We will save the discussion of most methods and features for the next section.  However, we will demonstrate now how to write a DataFrame to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:28:32.742000Z",
     "start_time": "2018-09-11T13:28:32.728000Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"data_2d_test_write.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try and read this file back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:28:37.850000Z",
     "start_time": "2018-09-11T13:28:37.827000Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test_read = pd.read_csv(\"data_2d_test_write.csv\")\n",
    "data_test_read.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the method also wrote the index as a column in the csv file.  When we read the file back in, Pandas created another index, so now we have two.  To avoid this, we can use the ```index``` argument in the ```to_csv``` method.  By default, this argument is set to ```True```, but we will set it to ```False```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:29:25.085000Z",
     "start_time": "2018-09-11T13:29:25.066000Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"data_2d_test_write.csv\", index = False)\n",
    "data_test_read = pd.read_csv(\"data_2d_test_write.csv\")\n",
    "data_test_read.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we read the file back in, we see that we don't have the pesky redundant indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common data format we encounter in industry is the Excel workbook.  An Excel workbook can be thought of as a collection of \"Sheets\", and each Sheet can be thought of as a table (read DataFrame).  To read data directly from an Excel file, we will need the package ```xlrd```, which should come with the Anaconda distribution.  If you don't have it, simply open the command prompt or terminal and type the following command.\n",
    "\n",
    "```conda install xlrd```\n",
    "\n",
    "Or, if you're not using Anaconda, use the normal pip install.\n",
    "\n",
    "```pip install xlrd```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:31:22.975000Z",
     "start_time": "2018-09-11T13:31:22.676000Z"
    }
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "\n",
    "data = pd.read_excel(\"excel_sample.xlsx\", sheetname = \"Sheet1\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that an Excel workbook may contain all kinds of structures under the hood, such as formulas, images, and macros.  Pandas can't read in these aspects of an Excel workbook, it can only read the data values in the cells.  When trying to read an Excel sheet with these aspects, best case scenario, it won't work and Python will simply read in the data, worst case scenario, Python will crash.\n",
    "\n",
    "To save a DataFrame as an Excel file, simply call the corresponding method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:31:58.531000Z",
     "start_time": "2018-09-11T13:31:58.478000Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_excel(\"excel_sample_write_test.xlsx\", sheet_name = \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:32:17.251000Z",
     "start_time": "2018-09-11T13:32:17.220000Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test_read = pd.read_excel(\"excel_sample_write_test.xlsx\", sheetname = \"Test\")\n",
    "data_test_read.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can also retrieve data from sources on the internet.  For this example, let's navigate to the web page https://www.fdic.gov/bank/individual/failed/banklist.html.  This page contains a table of failed banks with some additional information about the bank, such as the city, the bank's certification number, and when they failed.  Pandas can actually retrieve this table directly from the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:34:18.791000Z",
     "start_time": "2018-09-11T13:34:13.399000Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_html(\"https://www.fdic.gov/bank/individual/failed/banklist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see the type of our object ```data```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:34:25.744000Z",
     "start_time": "2018-09-11T13:34:25.737000Z"
    }
   },
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that ```data``` is actually an ordinary Python ```list``` instead of a DataFrame.  What the function ```pd.read_html``` has done is parse the entire web page looking for table markers.  Everywhere that the parser found a table marker in the html, it parsed the table and then stored that information in a list.  We now have to check what is in our list to see if we got what we were looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:36:02.802000Z",
     "start_time": "2018-09-11T13:36:02.795000Z"
    }
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, we see that in this case the function only found one table, so we can simply extract it from our list as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T13:36:18.270000Z",
     "start_time": "2018-09-11T13:36:18.231000Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[0]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that there are a lot of file formats out there (JSON, FWF, SAS, STATA, and many more), and Pandas has functions to read each of these formats.  The ones shown here are simply the most commonly encountered.  Pandas can also read data using SQL queries, but we'll cover this in detail when we cover SQL.  For now we will move on to the methods of DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic DataFrame Methods\n",
    "\n",
    "The first method you might've noticed is the ```head(n=5)``` method.  This allows us to get a quick glimpse at the structure of our table without trying to display the entire thing.  The default is for ```head()``` to output the first five rows of the DataFrame, but we can change the number of rows output by simply passing the number of rows we want to the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:24:00.989000Z",
     "start_time": "2018-08-20T10:24:00.940000Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at basic methods for querying DataFrames for information.  Here we will use the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T09:42:10.461000Z",
     "start_time": "2018-09-12T09:42:10.373000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"iris.csv\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we may want to format the names of our columns to better fit the style of the Python language.  There is also a more practical consideration in doing this.  Here we see that most of our column names contain the \".\" character.  This character is also used to call methods, and we don't want the Python interpreter to confuse part of a column name with a method.  This will almost certainly lead to errors that crash the Python interpreter, and may even lead to unexpected results.  We proceed with the rename method as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T09:50:38.304000Z",
     "start_time": "2018-09-12T09:50:38.289000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df \\\n",
    "    .rename(\n",
    "        columns = {\n",
    "            \"Sepal.Length\":\"sepal_length\",\n",
    "            \"Sepal.Width\":\"sepal_width\",\n",
    "            \"Petal.Length\":\"petal_length\",\n",
    "            \"Petal.Width\":\"petal_width\",\n",
    "            \"Species\":\"species\"},\n",
    "        inplace = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T09:50:40.022000Z",
     "start_time": "2018-09-12T09:50:39.990000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our columns are named as we would like them, we can look at methods for basic queries into the data.  We've seen that DataFrames are very similar to Python dictionaries.  Recall that a dictionary can be cast directly as a Pandas DataFrame and the keys will be interpreted as the column names, while the values will be taken as the columns themselves.  We can extend this analogy a little further by calling a column from our DataFrame in the same way we would call a value by its key name in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:48:08.455000Z",
     "start_time": "2018-08-20T10:48:08.416000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df[\"sepal_length\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the exact nature of this output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:08:07.387000Z",
     "start_time": "2018-09-12T10:08:07.379000Z"
    }
   },
   "outputs": [],
   "source": [
    "type(iris_df[\"sepal_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that each individual column in a Pandas DataFrame is actually a Pandas Series.  So, a DataFrame is just a collection of Series which share the same index.  It turns out the rows of the DataFrame can be thought of in this way as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:52:09.265000Z",
     "start_time": "2018-08-20T10:52:09.224000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:09:24.125000Z",
     "start_time": "2018-09-12T10:09:24.117000Z"
    }
   },
   "outputs": [],
   "source": [
    "type(iris_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row is a Pandas Series indexed by the column names in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call multiple columns at once by passing a list of column names into the brackets.  We will see that in this case the result is also a Pandas DataFrame, which is a sub frame of the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:10:05.432000Z",
     "start_time": "2018-09-12T10:10:05.407000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df[[\"sepal_length\", \"sepal_width\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:10:21.866000Z",
     "start_time": "2018-09-12T10:10:21.855000Z"
    }
   },
   "outputs": [],
   "source": [
    "type(iris_df[[\"sepal_length\", \"sepal_width\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at methods for subsetting the rows of a DataFrame.  We just saw in the above example that we can call rows by their index value using the ```iloc``` method.  Think of the ```loc``` as being \"location\", and the ```i``` as \"index.\"  So this method is for calling the index location of the desired row(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:10:55.251000Z",
     "start_time": "2018-09-12T10:10:55.216000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:11:20.967000Z",
     "start_time": "2018-09-12T10:11:20.946000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.iloc[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use slice notation to call ranges of rows in a DataFrame.  Just as with columns, when we call a single row, we get a Series; when we call multiple rows, we get a DataFrame.  We can also use the method to call columns after subsetting rows, so we can subset our DataFrame in multiple ways simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T11:16:59.834000Z",
     "start_time": "2018-08-20T11:16:59.818000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.iloc[0:10][\"sepal_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T11:17:51.423000Z",
     "start_time": "2018-08-20T11:17:51.407000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.iloc[0:10][[\"sepal_length\", \"sepal_width\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we won't be subsetting our DataFrames using row indexes, but rather with logical conditions.  For this we will use the ```loc``` method to simply find the locations that match our condition(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T11:21:10.849000Z",
     "start_time": "2018-08-20T11:21:10.826000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.loc[iris_df[\"sepal_length\"] > 5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:21:34.696000Z",
     "start_time": "2018-09-12T10:21:34.678000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.loc[(iris_df[\"sepal_length\"] > 5) & (iris_df[\"sepal_width\"] > 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use these methods to simultaneously call rows and columns, but we must use the same method in both axes to do this.  That is, we must use index values when using ```iloc```, and we must use conditions and key values when using ```loc```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:49:12.471000Z",
     "start_time": "2018-09-12T10:49:12.450000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.iloc[0:10, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:50:33.825000Z",
     "start_time": "2018-09-12T10:50:33.803000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.loc[\n",
    "    (iris_df[\"sepal_length\"] > 5) &\n",
    "    (iris_df[\"sepal_width\"] > 4),\n",
    "    [\"petal_length\",\n",
    "     \"petal_width\",\n",
    "     \"species\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to mix and match within the same method, we will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:51:03.006000Z",
     "start_time": "2018-09-12T10:51:02.966000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.iloc[0:10, \"sepal_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T10:52:28.780000Z",
     "start_time": "2018-09-12T10:52:28.695000Z"
    }
   },
   "outputs": [],
   "source": [
    "iris_df.loc[iris_df[\"sepal_width\"] > 4, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames also have some built-in methods for handling missing data.  This is an important consideration in any real world data science project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.dropna(inplace = True)\n",
    "\n",
    "iris_df \\\n",
    "    .loc[\"sepal_length\"] \\\n",
    "    .fillna(iris_df[\"sepal_length\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-Table Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, by=[\"vars\"], how=\"what type of join (left, right, inner, full)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T11:14:45.084000Z",
     "start_time": "2018-09-12T11:14:45.062000Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"subject\":[\"Math\", \"Biology\", \"Western Civilization\"],\n",
    "    \"Mid1\":[99, 98, 100],\n",
    "    \"Mid2\":[92, 97, 99],\n",
    "    \"Final\":[99, 98, 100]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T11:18:07.045000Z",
     "start_time": "2018-09-12T11:18:07.019000Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.melt(df, id_vars=\"subject\",\n",
    "        value_vars=[\"Mid1\", \"Mid2\", \"Final\"],\n",
    "        var_name = \"exam\",\n",
    "        value_name = \"score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T11:21:55.749000Z",
     "start_time": "2018-09-12T11:21:54.050000Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn; sn.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T11:21:56.069000Z",
     "start_time": "2018-09-12T11:21:56.063000Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 100)\n",
    "y = 2.7 + 1.4*x + np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T11:23:58.919000Z",
     "start_time": "2018-09-12T11:23:58.592000Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Fake Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T11:27:22.976000Z",
     "start_time": "2018-09-12T11:27:22.692000Z"
    }
   },
   "outputs": [],
   "source": [
    "u = 14 - 4.1*x + np.random.randn(100)\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.scatter(x,y, label = \"y\")\n",
    "plt.scatter(x,u, label = \"u\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T11:31:18.202000Z",
     "start_time": "2018-09-12T11:31:17.915000Z"
    }
   },
   "outputs": [],
   "source": [
    "z = np.random.randn(100)\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.hist(z)\n",
    "plt.xlim((-2,2))\n",
    "plt.xlabel(\"This is whatever z is\", fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
